{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy7g5ribCezupmeZgLe1a6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NathaliL/Recidivism-Prediction/blob/main/BERT_Recidivism_Classifier_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XlCFPdyQOpIl",
        "outputId": "fae8fb26-0c70-41f5-92da-3593b4ffb833"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.5)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "!pip install kaggle transformers scikit-learn pandas numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Kaggle API (Make sure to upload your kaggle.json file to the notebook environment)\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content'\n",
        "!kaggle datasets download -d uocoeeds/recidivism\n",
        "!unzip recidivism.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3AjwGIqO2j7",
        "outputId": "2ed37441-2445-4de9-80ba-86e1857c3045"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/uocoeeds/recidivism\n",
            "License(s): unknown\n",
            "recidivism.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  recidivism.zip\n",
            "replace recidivism_full.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "mIXhg_RpO8w7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and inspect the dataset from Kaggle\n",
        "df = pd.read_csv('recidivism_full.csv')\n",
        "print(df.head())\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZvMbRcFDPMB2",
        "outputId": "2c8dab14-854a-4f66-af91-522402da9690"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ID Gender   Race Age_at_Release  Residence_PUMA Gang_Affiliated  \\\n",
            "0   1      M  BLACK          43-47              16           False   \n",
            "1   2      M  BLACK          33-37              16           False   \n",
            "2   3      M  BLACK    48 or older              24           False   \n",
            "3   4      M  WHITE          38-42              16           False   \n",
            "4   5      M  WHITE          33-37              16           False   \n",
            "\n",
            "   Supervision_Risk_Score_First Supervision_Level_First  \\\n",
            "0                           3.0                Standard   \n",
            "1                           6.0             Specialized   \n",
            "2                           7.0                    High   \n",
            "3                           7.0                    High   \n",
            "4                           4.0             Specialized   \n",
            "\n",
            "         Education_Level Dependents  ... DrugTests_Meth_Positive  \\\n",
            "0  At least some college  3 or more  ...                0.000000   \n",
            "1   Less than HS diploma          1  ...                0.000000   \n",
            "2  At least some college  3 or more  ...                0.166667   \n",
            "3   Less than HS diploma          1  ...                0.000000   \n",
            "4   Less than HS diploma  3 or more  ...                0.058824   \n",
            "\n",
            "  DrugTests_Other_Positive Percent_Days_Employed Jobs_Per_Year  \\\n",
            "0                      0.0              0.488562      0.447610   \n",
            "1                      0.0              0.425234      2.000000   \n",
            "2                      0.0              0.000000      0.000000   \n",
            "3                      0.0              1.000000      0.718996   \n",
            "4                      0.0              0.203562      0.929389   \n",
            "\n",
            "  Employment_Exempt Recidivism_Within_3years Recidivism_Arrest_Year1  \\\n",
            "0             False                    False                   False   \n",
            "1             False                     True                   False   \n",
            "2             False                     True                   False   \n",
            "3             False                    False                   False   \n",
            "4             False                     True                    True   \n",
            "\n",
            "  Recidivism_Arrest_Year2  Recidivism_Arrest_Year3  Training_Sample  \n",
            "0                   False                    False                1  \n",
            "1                   False                     True                1  \n",
            "2                    True                    False                1  \n",
            "3                   False                    False                1  \n",
            "4                   False                    False                1  \n",
            "\n",
            "[5 rows x 54 columns]\n",
            "Index(['ID', 'Gender', 'Race', 'Age_at_Release', 'Residence_PUMA',\n",
            "       'Gang_Affiliated', 'Supervision_Risk_Score_First',\n",
            "       'Supervision_Level_First', 'Education_Level', 'Dependents',\n",
            "       'Prison_Offense', 'Prison_Years', 'Prior_Arrest_Episodes_Felony',\n",
            "       'Prior_Arrest_Episodes_Misd', 'Prior_Arrest_Episodes_Violent',\n",
            "       'Prior_Arrest_Episodes_Property', 'Prior_Arrest_Episodes_Drug',\n",
            "       'Prior_Arrest_Episodes_PPViolationCharges',\n",
            "       'Prior_Arrest_Episodes_DVCharges', 'Prior_Arrest_Episodes_GunCharges',\n",
            "       'Prior_Conviction_Episodes_Felony', 'Prior_Conviction_Episodes_Misd',\n",
            "       'Prior_Conviction_Episodes_Viol', 'Prior_Conviction_Episodes_Prop',\n",
            "       'Prior_Conviction_Episodes_Drug',\n",
            "       'Prior_Conviction_Episodes_PPViolationCharges',\n",
            "       'Prior_Conviction_Episodes_DomesticViolenceCharges',\n",
            "       'Prior_Conviction_Episodes_GunCharges', 'Prior_Revocations_Parole',\n",
            "       'Prior_Revocations_Probation', 'Condition_MH_SA', 'Condition_Cog_Ed',\n",
            "       'Condition_Other', 'Violations_ElectronicMonitoring',\n",
            "       'Violations_Instruction', 'Violations_FailToReport',\n",
            "       'Violations_MoveWithoutPermission', 'Delinquency_Reports',\n",
            "       'Program_Attendances', 'Program_UnexcusedAbsences', 'Residence_Changes',\n",
            "       'Avg_Days_per_DrugTest', 'DrugTests_THC_Positive',\n",
            "       'DrugTests_Cocaine_Positive', 'DrugTests_Meth_Positive',\n",
            "       'DrugTests_Other_Positive', 'Percent_Days_Employed', 'Jobs_Per_Year',\n",
            "       'Employment_Exempt', 'Recidivism_Within_3years',\n",
            "       'Recidivism_Arrest_Year1', 'Recidivism_Arrest_Year2',\n",
            "       'Recidivism_Arrest_Year3', 'Training_Sample'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the text and label columns\n",
        "# Assume the column 'text_column' contains the text data you want to use with BERT\n",
        "texts = df['ID'].astype(str).tolist()  # Convert to list of strings (\n",
        "labels = df['Training_Sample']  # Assuming 'recidivism_column' is the column containing labels"
      ],
      "metadata": {
        "id": "Xm-ZdnEUPrC_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased').to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "si0-yxD8RBww",
        "outputId": "40dd57a3-3944-47ee-fb19-92674bccfdcc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embeddings(text_list, batch_size=32):\n",
        "    embeddings = []\n",
        "    for i in range(0, len(text_list), batch_size):\n",
        "        batch_texts = text_list[i:i+batch_size]\n",
        "        inputs = tokenizer(batch_texts, return_tensors='pt', truncation=True, padding=True, max_length=512).to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "            batch_embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
        "            embeddings.append(batch_embeddings)\n",
        "    return np.vstack(embeddings)"
      ],
      "metadata": {
        "id": "OwzXx-_RRL6U"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for the entire dataset\n",
        "embeddings = get_embeddings(texts)"
      ],
      "metadata": {
        "id": "aIYn27KeRSW8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KcRQhWWlUk71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerical_features = df[['Residence_PUMA', 'Jobs_Per_Year' ,'Supervision_Risk_Score_First']]\n",
        "# Combine embeddings with numerical features\n",
        "features = np.hstack((embeddings, numerical_features.values))"
      ],
      "metadata": {
        "id": "KaA6Xt0nTiuq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "valid_idx = ~np.isnan(features).any(axis=1)\n",
        "features = features[valid_idx]\n",
        "labels = labels[valid_idx]"
      ],
      "metadata": {
        "id": "H1W0xil9U9QH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Logistic Regression classifier\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ngM7FjtCV79l",
        "outputId": "42010a88-621b-4f08-85bc-e22f5b6a8aba"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict and evaluate the classifier\n",
        "# y_pred = clf.predict(X_test)\n",
        "# accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision = precision_score(y_test, y_pred, average='binary')\n",
        "# recall = recall_score(y_test, y_pred, average='binary')\n",
        "# f1 = f1_score(y_test, y_pred, average='binary')\n",
        "\n",
        "# print(f\"Accuracy: {accuracy}\")\n",
        "# print(f\"Precision: {precision}\")\n",
        "# print(f\"Recall: {recall}\")\n",
        "# print(f\"F1 Score: {f1}\")\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Assume the BERT embeddings are stored in a list called embeddings\n",
        "X = np.array(embeddings)  # Convert list of embeddings to a NumPy array\n",
        "y = df['Training_Sample'].values  # Convert labels to a NumPy array\n",
        "\n",
        "kf5 = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "kf10 = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "def train_and_evaluate_kfold(kf, X, y):\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1s = []\n",
        "\n",
        "    for train_index, test_index in kf.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        # Train your model (e.g., logistic regression)\n",
        "        model = LogisticRegression()\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Evaluate model\n",
        "        accuracies.append(accuracy_score(y_test, y_pred))\n",
        "        precisions.append(precision_score(y_test, y_pred))\n",
        "        recalls.append(recall_score(y_test, y_pred))\n",
        "        f1s.append(f1_score(y_test, y_pred))\n",
        "\n",
        "    # Return all values for accuracy, precision, recall, and F1 score\n",
        "    return accuracies, precisions, recalls, f1s\n",
        "\n",
        "# Example usage for k=5:\n",
        "acc_5, prec_5, rec_5, f1_5 = train_and_evaluate_kfold(kf5, X, y)\n",
        "print(f\"K=5 Fold Accuracy: {acc_5}\")\n",
        "print(f\"K=5 Fold Precision: {prec_5}\")\n",
        "print(f\"K=5 Fold Recall: {rec_5}\")\n",
        "print(f\"K=5 Fold F1 Score: {f1_5}\")\n",
        "\n",
        "# Example usage for k=10:\n",
        "acc_10, prec_10, rec_10, f1_10 = train_and_evaluate_kfold(kf10, X, y)\n",
        "print(f\"K=10 Fold Accuracy: {acc_10}\")\n",
        "print(f\"K=10 Fold Precision: {prec_10}\")\n",
        "print(f\"K=10 Fold Recall: {rec_10}\")\n",
        "print(f\"K=10 Fold F1 Score: {f1_10}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9jpcYIYWLqo",
        "outputId": "d98263fc-1598-4556-8842-6268450ebbf0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K=5 Fold Accuracy: [0.6980839945809948, 0.6957615637700794, 0.6951809560673505, 0.6907296303464293, 0.6895684149409715]\n",
            "K=5 Fold Precision: [0.7012480499219969, 0.7001756783134881, 0.698828125, 0.6924271844660194, 0.6937182988685134]\n",
            "K=5 Fold Recall: [0.9922737306843267, 0.9900634833011317, 0.9908612572694544, 0.9960893854748604, 0.9905292479108635]\n",
            "K=5 Fold F1 Score: [0.8217550274223033, 0.8202606906014177, 0.8196082922918337, 0.8169530355097365, 0.8159706287287747]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K=10 Fold Accuracy: [0.7058823529411765, 0.6927244582043344, 0.7047213622291022, 0.6938854489164087, 0.6904024767801857, 0.6995741385985288, 0.6895083236546651, 0.6887340301974448, 0.699961285327139, 0.6840882694541232]\n",
            "K=10 Fold Precision: [0.7082362082362083, 0.6937111801242236, 0.7051978277734678, 0.6964632724446171, 0.6927265655387009, 0.703862660944206, 0.6915306915306916, 0.6922477600311648, 0.7028816199376947, 0.6862592448423511]\n",
            "K=10 Fold Recall: [0.9950873362445415, 0.9972098214285714, 0.9983525535420099, 0.9944506104328524, 0.9944165270798436, 0.9906644700713894, 0.9955257270693513, 0.9921831379117811, 0.9933957072096863, 0.9943598420755781]\n",
            "K=10 Fold F1 Score: [0.8275079437131184, 0.8182234432234432, 0.826551488974767, 0.8192, 0.816597890875745, 0.822992700729927, 0.8161393856029345, 0.8155117026158789, 0.8232611174458381, 0.8120681713496085]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6s-uQTKKMVby"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}